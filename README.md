# KoE5: í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸

## Update Logs
- 2024.10.02: [ğŸ¤—KoE5](https://huggingface.co/nlpai-lab/KoE5)), [ğŸ¤—ko-triplet-v1.0](https://huggingface.co/datasets/nlpai-lab/ko-triplet-v1.0) ê³µê°œ

---

<br>

KoE5ëŠ” ê³ ë ¤ëŒ€í•™êµ [NLP & AI ì—°êµ¬ì‹¤](http://nlp.korea.ac.kr/)ê³¼ [HIAI ì—°êµ¬ì†Œ](http://hiai.korea.ac.kr)ê°€ ê°œë°œí•œ í•œêµ­ì–´ íŠ¹í™” ì„ë² ë”© ëª¨ë¸ì…ë‹ˆë‹¤.

KoE5ë¥¼ ê³µê°œí•©ë‹ˆë‹¤.  
<br/>

## KoE5 ê²€ìƒ‰ ì„±ëŠ¥ ê²°ê³¼
<img src="assets/koe5-evaluation.png" >

## KoE5 ëª¨ë¸ ì‹¤í–‰ ì½”ë“œ
### sentence-transformersë¡œ ì‹¤í–‰
```bash
pip install sentence-transformers
```

ì•„ë˜ ì˜ˆì œ ì½”ë“œë¡œ ì‹¤í–‰í•´ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.

```python
from sentence_transformers import SentenceTransformer

# Download from the ğŸ¤— Hub
model = SentenceTransformer("nlpai-lab/KoE5")

# Run inference
sentences = [
    'query: í—Œë²•ê³¼ ë²•ì›ì¡°ì§ë²•ì€ ì–´ë–¤ ë°©ì‹ì„ í†µí•´ ê¸°ë³¸ê¶Œ ë³´ì¥ ë“±ì˜ ë‹¤ì–‘í•œ ë²•ì  ëª¨ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í–ˆì–´',
    'passage: 4. ì‹œì‚¬ì ê³¼ ê°œì„ ë°©í–¥ ì•ì„œ ì‚´í´ë³¸ ë°”ì™€ ê°™ì´ ìš°ë¦¬ í—Œë²•ê³¼ ï½¢ë²•ì›ì¡°ì§ ë²•ï½£ì€ ëŒ€ë²•ì› êµ¬ì„±ì„ ë‹¤ì–‘í™”í•˜ì—¬ ê¸°ë³¸ê¶Œ ë³´ì¥ê³¼ ë¯¼ì£¼ì£¼ì˜ í™•ë¦½ì— ìˆì–´ ë‹¤ê°ì ì¸ ë²•ì  ëª¨ìƒ‰ì„ ê°€ëŠ¥í•˜ê²Œ í•˜ëŠ” ê²ƒì„ ê·¼ë³¸ ê·œë²”ìœ¼ë¡œ í•˜ê³  ìˆë‹¤. ë”ìš±ì´ í•©ì˜ì²´ë¡œì„œì˜ ëŒ€ë²•ì› ì›ë¦¬ë¥¼ ì±„íƒí•˜ê³  ìˆëŠ” ê²ƒ ì—­ì‹œ ê·¸ êµ¬ì„±ì˜ ë‹¤ì–‘ì„±ì„ ìš”ì²­í•˜ëŠ” ê²ƒìœ¼ë¡œ í•´ì„ëœë‹¤. ì´ì™€ ê°™ì€ ê´€ì ì—ì„œ ë³¼ ë•Œ í˜„ì§ ë²•ì›ì¥ê¸‰ ê³ ìœ„ë²•ê´€ì„ ì¤‘ì‹¬ìœ¼ë¡œ ëŒ€ë²•ì›ì„ êµ¬ì„±í•˜ëŠ” ê´€í–‰ì€ ê°œì„ í•  í•„ìš”ê°€ ìˆëŠ” ê²ƒìœ¼ë¡œ ë³´ì¸ë‹¤.',
    'passage: ì—°ë°©í—Œë²•ì¬íŒì†ŒëŠ” 2001ë…„ 1ì›” 24ì¼ 5:3ì˜ ë‹¤ìˆ˜ê²¬í•´ë¡œ ã€Œë²•ì›ì¡°ì§ë²•ã€ ì œ169ì¡° ì œ2ë¬¸ì´ í—Œë²•ì— í•©ì¹˜ëœë‹¤ëŠ” íŒê²°ì„ ë‚´ë ¸ìŒ â—‹ 5ì¸ì˜ ë‹¤ìˆ˜ ì¬íŒê´€ì€ ì†Œì†¡ê´€ê³„ì¸ì˜ ì¸ê²©ê¶Œ ë³´í˜¸, ê³µì •í•œ ì ˆì°¨ì˜ ë³´ì¥ê³¼ ë°©í•´ë°›ì§€ ì•ŠëŠ” ë²•ê³¼ ì§„ì‹¤ ë°œê²¬ ë“±ì„ ê·¼ê±°ë¡œ í•˜ì—¬ í…”ë ˆë¹„ì „ ì´¬ì˜ì— ëŒ€í•œ ì ˆëŒ€ì ì¸ ê¸ˆì§€ë¥¼ í—Œë²•ì— í•©ì¹˜í•˜ëŠ” ê²ƒìœ¼ë¡œ ë³´ì•˜ìŒ â—‹ ê·¸ëŸ¬ë‚˜ ë‚˜ë¨¸ì§€ 3ì¸ì˜ ì¬íŒê´€ì€ í–‰ì •ë²•ì›ì˜ ì†Œì†¡ì ˆì°¨ëŠ” íŠ¹ë³„í•œ ì¸ê²©ê¶Œ ë³´í˜¸ì˜ ì´ìµë„ ì—†ìœ¼ë©°, í…”ë ˆë¹„ì „ ê³µê°œì£¼ì˜ë¡œ ì¸í•´ ë²•ê³¼ ì§„ì‹¤ ë°œê²¬ì˜ ê³¼ì •ì´ ì–¸ì œë‚˜ ìœ„íƒœë¡­ê²Œ ë˜ëŠ” ê²ƒì€ ì•„ë‹ˆë¼ë©´ì„œ ë°˜ëŒ€ì˜ê²¬ì„ ì œì‹œí•¨ â—‹ ì™œëƒí•˜ë©´ í–‰ì •ë²•ì›ì˜ ì†Œì†¡ì ˆì°¨ì—ì„œëŠ” ì†Œì†¡ë‹¹ì‚¬ìê°€ ê°œì¸ì ìœ¼ë¡œ ì§ì ‘ ì‹¬ë¦¬ì— ì°¸ì„í•˜ê¸°ë³´ë‹¤ëŠ” ë³€í˜¸ì‚¬ê°€ ì°¸ì„í•˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©°, ì‹¬ë¦¬ëŒ€ìƒë„ ì‚¬ì‹¤ë¬¸ì œê°€ ì•„ë‹Œ ë²•ë¥ ë¬¸ì œê°€ ëŒ€ë¶€ë¶„ì´ê¸° ë•Œë¬¸ì´ë¼ëŠ” ê²ƒì„ â–¡ í•œí¸, ì—°ë°©í—Œë²•ì¬íŒì†ŒëŠ” ã€Œì—°ë°©í—Œë²•ì¬íŒì†Œë²•ã€(Bundesverfassungsgerichtsgesetz: BVerfGG) ì œ17aì¡°ì— ë”°ë¼ ì œí•œì ì´ë‚˜ë§ˆ ì¬íŒì— ëŒ€í•œ ë°©ì†¡ì„ í—ˆìš©í•˜ê³  ìˆìŒ â—‹ ã€Œì—°ë°©í—Œë²•ì¬íŒì†Œë²•ã€ ì œ17ì¡°ì—ì„œ ã€Œë²•ì›ì¡°ì§ë²•ã€ ì œ14ì ˆ ë‚´ì§€ ì œ16ì ˆì˜ ê·œì •ì„ ì¤€ìš©í•˜ë„ë¡ í•˜ê³  ìˆì§€ë§Œ, ë…¹ìŒì´ë‚˜ ì´¬ì˜ì„ í†µí•œ ì¬íŒê³µê°œì™€ ê´€ë ¨í•˜ì—¬ì„œëŠ” ã€Œë²•ì›ì¡°ì§ë²•ã€ê³¼ ë‹¤ë¥¸ ë‚´ìš©ì„ ê·œì •í•˜ê³  ìˆìŒ',
]
embeddings = model.encode(sentences)
print(embeddings.shape)
# [3, 1024]

# Get the similarity scores for the embeddings
similarities = model.similarity(embeddings, embeddings)
print(similarities)
# tensor([[1.0000, 0.6721, 0.3897],
#        [0.6721, 1.0000, 0.3740],
#        [0.3897, 0.3740, 1.0000]])
```

<br/>

## Training Details
KoE5ëŠ” [intfloat/multilingual-e5-large](https://huggingface.co/intfloat/multilingual-e5-large)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ fine-tuningëœ ëª¨ë¸ì…ë‹ˆë‹¤.
### Training Data
- [ko-triplet-v1.0](https://huggingface.co/datasets/nlpai-lab/ko-triplet-v1.0)
- í•œêµ­ì–´ query-document-hard_negative ë°ì´í„° ìŒ (open data)
- ì•½ 700000+ examples

### Training Procedure
- **loss:** Sentence-transformersì˜ **[CachedMultipleNegativesRankingLoss](https://sbert.net/docs/package_reference/sentence_transformer/losses.html#cachedmultiplenegativesrankingloss)** ì„ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
- **batch size:** 512
- **learning rate:** 1e-05
- **epochs:** 1

<br/>

## Evaluation
### Metrics
- NDCG@1, F1@1, NDCG@3, F1@3
### Benchmark Datasets
- Ko-strategyQA
- AutoRAG-benchmark
- PublicHealthQA

<br/>

## ì£¼ì˜ì‚¬í•­

- í•™ìŠµ ì‹œ ì‚¬ìš©ëœ prefixë¥¼ ë¶™ì—¬ ì£¼ì–´ì•¼ í•©ë‹ˆë‹¤. (query: {query}, passage: {positive}, document: {negative})
  
## License
- ```MIT```

## Citation

If you find our paper or models helpful, please consider cite as follows:
```text
@misc{KoE5,
  author = {NLP & AI Lab and Human-Inspired AI research},
  title = {KoE5: A New Dataset and Model for Improving Korean Embedding Performance},
  year = {2024},
  publisher = {Youngjoon Jang, Junyoung Son, Taemin Lee},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/nlpai-lab/KoE5}},
}
```
